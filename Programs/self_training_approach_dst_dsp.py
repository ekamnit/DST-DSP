# -*- coding: utf-8 -*-
"""Self_training_Approach_DST-DSP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11y9y5HQN76O_fdEVCmz_3-R9Ay3BKZ6x
"""

import os
import pandas as pd
import numpy as np
from pandas import read_csv
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import f1_score
from sklearn import metrics
from sklearn.metrics import confusion_matrix
from sklearn.linear_model import LogisticRegression
from imblearn.over_sampling import ADASYN
from sklearn.model_selection import cross_val_score
from sklearn.semi_supervised import SelfTrainingClassifier
from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV

from google.colab import drive
drive.mount('/content/gdrive')

df=pd.read_excel('/content/gdrive/MyDrive/Work2-CPDP-Replication/AEEEM/eclipse.xlsx')
df

print("defective ",len(df[df['Nondefective'] ==0]))

unlabelled_df = df.loc[(df['Nondefective']==0)&(df[' highPriorityBugs ']==0)&(df[' criticalBugs ']==0)&(df[' majorBugs ']==0)&(df[' nonTrivialBugs ']==0)]

print(unlabelled_df.shape)

labelled_df = df.loc[~((df['Nondefective']==0)&(df[' highPriorityBugs ']==0)&(df[' criticalBugs ']==0)&(df[' majorBugs ']==0)&(df[' nonTrivialBugs ']==0))]

print(labelled_df.shape)

df.columns

"""# Generating **x,y**"""

data =labelled_df.values
idx_OUT_columns = [10,9,8,7,6]
idx_IN_columns = [i for i in range(np.shape(data)[1]) if i not in idx_OUT_columns]
x = data[:,idx_IN_columns]
x = x[:,1:]
y = data[:,idx_OUT_columns]
y=y.astype('int')
print("x : ",x)
print("y : ",y)

data =unlabelled_df.values
idx_OUT_columns = [10,9,8,7,6]
idx_IN_columns = [i for i in range(np.shape(data)[1]) if i not in idx_OUT_columns]
X_unlabelled = data[:,idx_IN_columns]
X_unlabelled = X_unlabelled[:,1:]

oversample = ADASYN(n_neighbors=1)
X, Y = oversample.fit_resample(x, y)

"""# **Classes**"""

def counting(y):
  count=[0,0,0,0,0]
  for i in range(len(y)):
    k=0
    for j in range(5):
      if(y[i][j]==1):
        count[j]+=1
  print("no of nonTrivialBugs ",count[3])
  print("no of majorBugs ",count[2])
  print("no of criticalBugs ",count[1])
  print("no of highPriorityBugs ",count[0])
  print("no of Nondefective modules ",count[4])
  return count;

counting(Y)

"""# **Self-Training Semi Supervised Learning Approach for SDSP**"""

# Initiate iteration counter

iterations = 0

# Containers to hold f1_scores and # of pseudo-labels
train_f1s = []
test_f1s = []
pseudo_labels = []

# Assign value to initiate while loop
high_prob = [1]

Y=np.argmax(Y,axis=1)

cnt=0
while len(X_unlabelled) > 0:

    # Fit classifier and make train/test predictions
    clf =  DecisionTreeClassifier()
    param_grid = {
    'criterion': ['gini', 'entropy'],
    'splitter': ['best', 'random'],
    'max_depth': [None, 10, 20, 30, 40, 50],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4],
    'max_features': [None, 'auto', 'sqrt', 'log2']
    }
    # Initialize GridSearchCV with the decision tree and parameter grid
    np.clongfloat = GridSearchCV(estimator=clf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)
    # Perform 10-fold cross-validation
    cv_scores = cross_val_score(clf, X, y, cv=10)
    # Fit GridSearchCV to the training data
    clf.fit(X, Y)
    best_params = clf.best_params_
    # clf.fit(X, Y)
    y_hat_train = clf.predict(X)

    # Calculate and print iteration # and f1 scores, and store f1 scores
    train_f1 = f1_score(Y, y_hat_train,average='micro')
    print(f"Iteration {iterations}")
    print(f"Train f1: {train_f1}")
    train_f1s.append(train_f1)

    # Generate predictions and probabilities for unlabeled data
    print(f"Now predicting labels for unlabeled data...")

    preds = clf.predict(X_unlabelled)
    pred_probs = clf.predict_proba(X_unlabelled)

    prob_0 = [row[0] for row in pred_probs]
    prob_1 = [row[1] for row in pred_probs]
    prob_2 = [row[2] for row in pred_probs]
    prob_3 = [row[3] for row in pred_probs]
    prob_4 = [row[4] for row in pred_probs]

    # Store predictions and probabilities in dataframe
    df_pred_prob = pd.DataFrame([])

    df_pred_prob['preds'] = preds
    df_pred_prob['prob_0'] = prob_0
    df_pred_prob['prob_1'] = prob_1
    df_pred_prob['prob_2'] = prob_2
    df_pred_prob['prob_3'] = prob_3
    df_pred_prob['prob_4'] = prob_4
    df_pred_prob.index = [i for i in range(len(X_unlabelled))]
    k=0.99
    # Separate predictions with > 99% probability
    high_prob = pd.concat([df_pred_prob.loc[df_pred_prob['prob_0'] > k],
                           df_pred_prob.loc[df_pred_prob['prob_1'] > k],df_pred_prob.loc[df_pred_prob['prob_2'] > k],
                           df_pred_prob.loc[df_pred_prob['prob_3'] > k],df_pred_prob.loc[df_pred_prob['prob_4'] > k]],
                          axis=0)

    print(f"{len(high_prob)} high-probability predictions added to training data.")

    pseudo_labels.append(len(high_prob))

    # Add pseudo-labeled data to training data
    if(high_prob.empty==False):
      X = np.vstack((X,X_unlabelled[high_prob.index]))
      y_pred  = np.array(high_prob.preds)
      Y = np.hstack((Y,y_pred))

      # Drop pseudo-labeled instances from unlabeled data
      idx_predict = [i for i in range(np.shape(X_unlabelled)[0]) if i not in high_prob.index]
      X_unlabelled = X_unlabelled[idx_predict]
      print(f"{len(X_unlabelled)} unlabeled instances remaining.\n")
    else :
      break;
    # Update iteration counter
    iterations += 1

"""## **Performance Measures**"""

def Function(clf):
  clf.fit(X, Y)
  y_hat_train = clf.predict(X)
  train_f1 = f1_score(Y, y_hat_train,average='micro')
  print(f"Train f1: {train_f1}")
  df=pd.read_excel('/content/gdrive/MyDrive/Btech_Project/CombinedDataset/pde.xlsx')
  labelled_df = df.loc[~((df['Nondefective']==0)&(df[' highPriorityBugs ']==0)&(df[' criticalBugs ']==0)&(df[' majorBugs ']==0)&(df[' nonTrivialBugs ']==0))]
  data =labelled_df.values
  idx_OUT_columns = [10,9,8,7,6]
  idx_IN_columns = [i for i in range(np.shape(data)[1]) if i not in idx_OUT_columns]
  x_test = data[:,idx_IN_columns]
  x_test = x_test[:,1:]
  y_test = data[:,idx_OUT_columns]
  y_test=y_test.astype('int')
  y_test=np.argmax(y_test,axis=1)
  yhat_test= clf.predict(x_test)
  yhat_pred_probs = clf.predict_proba(x_test)
  print("test f1score : ",f1_score(y_test, yhat_test,average='micro'))
  CM=confusion_matrix(y_test, yhat_test,labels=[0,1,2,3,4])

  print(CM)

  Risk_HP=((0.1*CM[0][1])+(0.2*CM[0][2])+(0.3*CM[0][3])+(0.4*CM[0][4]))/(CM[0][0]+CM[0][1]+CM[0][2]+CM[0][3]+CM[0][4])
  Risk_C=((0.1*CM[1][2])+(0.2*CM[1][3])+(0.3*CM[1][4]))/(CM[1][0]+CM[1][1]+CM[1][2]+CM[1][3]+CM[1][4])
  Risk_M=((0.1*CM[2][3])+(0.2*CM[2][4]))/(CM[2][0]+CM[2][1]+CM[2][2]+CM[2][3]+CM[2][4])
  Risk_NT=(0.1*CM[3][4])/(CM[3][0]+CM[3][1]+CM[3][2]+CM[3][3]+CM[4][4])
  print("Risk Factor for High Priority",Risk_HP)
  print("Risk Factor for Critical",Risk_C)
  print("Risk Factor for Major",Risk_M)
  print("Risk Factor for Non-Trivial",Risk_NT)
  print('PTN:',CM[4][4],'/',len(x_test),'=',CM[4][4]/len(x_test))
  total_loc=0
  tn_loc=0
  for i in range(len(x_test)):
    total_loc=total_loc+x_test[i][28]
    if((yhat_test[i]==4)and(y_test[i]==4)):
      tn_loc=tn_loc+x_test[i][28]
  print('Saved Budget:',tn_loc)
  print('PSB:',tn_loc/total_loc)
  print('PNTN:',(1-(CM[4][4]/len(x_test))))
  print('Remaining Servie Time:',total_loc-tn_loc)
  print('PRST:',(1-(tn_loc/total_loc)))

Function(LogisticRegression());

Function(DecisionTreeClassifier())